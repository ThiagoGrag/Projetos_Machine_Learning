{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'>Thiago</font>\n",
    "## <font color='gray'>Machine Learning</font>\n",
    "\n",
    "## <font color='gray'>Regressão</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Múltipla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo o Problema de Negócio\n",
    "\n",
    "Nosso objetivo é construir um modelo de Machine Learning que seja capaz de fazer previsões sobre a taxa média de ocupação de casas na região de Boston, EUA, por proprietários. A variável a ser prevista é um valor numérico que representa a mediana da taxa de ocupação das casas em Boston. Para cada casa temos diversas variáveis explanatórias. Sendo assim, podemos resolver este problema empregando Regressão Linear Simples ou Múltipla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo o Dataset \n",
    "\n",
    "Usaremos o Boston Housing Dataset, que é um conjunto de dados que tem a taxa média de ocupação das casas, juntamente com outras 13 variáveis que podem estar relacionadas aos preços das casas. Esses são os fatores como condições socioeconômicas, condições ambientais, instalações educacionais e alguns outros fatores semelhantes. Existem 506 observações nos dados para 14 variáveis. Existem 12 variáveis numéricas em nosso conjunto de dados e 1 variável categórica. O objetivo deste projeto é construir um modelo de regressão linear para estimar a taxa média de ocupação das casas pelos proprietários em Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/housing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CRIM: per capita crime rate by town \n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. INDUS: proportion of non-residential acres per town \n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "6. RM: average number of rooms per dwelling \n",
    "7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "8. DIS: weighted distances to five Boston employment centres \n",
    "9. RAD: index of accessibility to radial highways \n",
    "10. TAX: full-value property-tax rate per 10,000 \n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population \n",
    "14. TARGET: Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Thiago Gragnanello\n",
      "\n",
      "sklearn    : 1.0.2\n",
      "numpy      : 1.26.1\n",
      "statsmodels: 0.13.2\n",
      "pandas     : 1.4.4\n",
      "matplotlib : 3.5.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Thiago Gragnanello\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando número de observações e variáveis\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando x e y\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variáveis explanatórias\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variável target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Múltiplos Atributos com StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = sm.add_constant(X)\n",
    "modelo = sm.OLS(y, Xc)\n",
    "modelo_v1 = modelo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 17 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:24:39</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Tue, 17 Oct 2023   Prob (F-statistic):          6.72e-135\n",
       "Time:                        20:24:39   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "ZN             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "CHAS           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "RM             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "AGE            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "RAD            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "B              0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_v1.summary()\n",
    "\n",
    "## Valor P é um indicativo de associação, quanto menor o valor de P, maior a associação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
      "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
      "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
      "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
      "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
      "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
      "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
      "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
      "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
      "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
      "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
      "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
      "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
      "\n",
      "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
      "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
      "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
      "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
      "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
      "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
      "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
      "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
      "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
      "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
      "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
      "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
      "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
      "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Gerando a matriz\n",
    "X = dataset.iloc[:,:-1]\n",
    "matriz_corr = X.corr()\n",
    "print (matriz_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Correlation Plot\n",
    "def visualize_correlation_matrix(data, hurdle = 0.0):\n",
    "    R = np.corrcoef(data, rowvar = 0)\n",
    "    R[np.where(np.abs(R) < hurdle)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap = mpl.cm.coolwarm, alpha = 0.8)\n",
    "    heatmap.axes.set_frame_on(False)\n",
    "    heatmap.axes.set_yticks(np.arange(R.shape[0]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticks(np.arange(R.shape[1]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticklabels(variables, minor = False)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.axes.set_yticklabels(variables, minor = False)\n",
    "    plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off') \n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando o Plot\n",
    "visualize_correlation_matrix(X, hurdle = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a Multicolinearidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autovalores (Eigenvalues) e Autovetores (Eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma ainda mais automática de detectar associações multicolineares (e descobrir problemas numéricos em uma inversão de matriz) é usar autovetores. Explicados em termos simples, os autovetores são uma maneira muito inteligente de recombinar a variância entre as variáveis, criando novos recursos acumulando toda a variância compartilhada. Tal recombinação pode ser obtida usando a função NumPy linalg.eig, resultando em um vetor de autovalores (representando a quantidade de variância recombinada para cada nova variável) e autovetores (uma matriz nos dizendo como as novas variáveis se relacionam com as antigas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando eigenvalues e eigenvectors\n",
    "corr = np.corrcoef(X, rowvar = 0)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de extrair os autovalores, imprimimos em ordem decrescente e procuramos qualquer elemento cujo valor seja próximo de zero ou pequeno em comparação com os outros. Valores próximos a zero podem representar um problema real para equações normais e outros métodos de otimização baseados na inversão matricial. Valores pequenos representam uma fonte elevada, mas não crítica, de multicolinearidade. Se você detectar qualquer um desses valores baixos, anote a posição no vetor (lembre-se que os índices em Python começam por zero). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O menor valor está na posição 8. Vamos buscar a posição 8 no autovetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.12684883 1.43327512 1.24261667 0.85757511 0.83481594 0.65740718\n",
      " 0.53535609 0.39609731 0.06350926 0.27694333 0.16930298 0.18601437\n",
      " 0.22023782]\n"
     ]
    }
   ],
   "source": [
    "print (eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a posição do índice na lista de autovalores, podemos encontrar o vetor específico nos autovetores que contém as variáveis carregadas, ou seja, o nível de associação com os valores originais. No eigenvector, observamos valores nas posições de índice 2, 8 e 9, que estão realmente em destaque em termos de valor absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0459523   0.08091897  0.25107654 -0.03592171 -0.04363045 -0.0455671\n",
      "  0.03855068  0.01829854  0.63348972 -0.72023345 -0.02339805  0.00446307\n",
      " -0.02443168]\n"
     ]
    }
   ],
   "source": [
    "print (eigenvectors[:,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora nós imprimimos os nomes das variáveis para saber quais contribuem mais com seus valores para construir o autovetor. Associamos o vetor de variáveis com o eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUS RAD TAX\n"
     ]
    }
   ],
   "source": [
    "print (variables[2], variables[8], variables[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo encontrado os culpados da multicolinearidade, o que devemos fazer com essas variáveis? A remoção de algumas delas é geralmente a melhor solução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os dados\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar Feature Scaling através de Padronização ou Normalização. Normalização aplica escala aos dados com intervalos entre 0 e 1. A Padronização divide a média pelo desvio padrão para obter uma unidade de variância. Vamos usar a Padronização (StandardScaler) pois nesse caso esta técnica ajusta os coeficientes e torna a superfície de erros mais \"tratável\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando Padronização\n",
    "standardization = StandardScaler()\n",
    "Xst = standardization.fit_transform(X)\n",
    "original_means = standardization.mean_\n",
    "originanal_stds = standardization.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando X e Y\n",
    "Xst = np.column_stack((Xst,np.ones(observations)))\n",
    "y  = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def random_w( p ):\n",
    "    return np.array([np.random.normal() for j in range(p)])\n",
    "\n",
    "def hypothesis(X,w):\n",
    "    return np.dot(X,w)\n",
    "\n",
    "def loss(X,w,y):\n",
    "    return hypothesis(X,w) - y\n",
    "\n",
    "def squared_loss(X,w,y):\n",
    "    return loss(X,w,y)**2\n",
    "\n",
    "def gradient(X,w,y):\n",
    "    gradients = list()\n",
    "    n = float(len( y ))\n",
    "    for j in range(len(w)):\n",
    "        gradients.append(np.sum(loss(X,w,y) * X[:,j]) / n)\n",
    "    return gradients\n",
    "\n",
    "def update(X,w,y, alpha = 0.01):\n",
    "    return [t - alpha*g for t, g in zip(w, gradient(X,w,y))]\n",
    "\n",
    "def optimize(X,y, alpha = 0.01, eta = 10**-12, iterations = 1000):\n",
    "    w = random_w(X.shape[1])\n",
    "    path = list()\n",
    "    for k in range(iterations):\n",
    "        SSL = np.sum(squared_loss(X,w,y))\n",
    "        new_w = update(X,w,y, alpha = alpha)\n",
    "        new_SSL = np.sum(squared_loss(X,new_w,y))\n",
    "        w = new_w\n",
    "        if k>=5 and (new_SSL - SSL <= eta and new_SSL - SSL >= -eta):\n",
    "            path.append(new_SSL)\n",
    "            return w, path\n",
    "        if k % (iterations / 20) == 0:\n",
    "            path.append(new_SSL)\n",
    "    return w, path                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes finais padronizados: -0.9281, 1.0816, 0.1409, 0.6817, -2.0567, 2.6742, 0.0195, -3.1040, 2.6622, -2.0768, -2.0606, 0.8493, -3.7436, 22.5328\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o resultado                           \n",
    "alpha = 0.01\n",
    "w, path = optimize(Xst, y, alpha, eta = 10**-12, iterations = 20000)\n",
    "print (\"Coeficientes finais padronizados: \" + ', '.join(map(lambda x: \"%0.4f\" % x, w)))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desfazendo a Padronização\n",
    "unstandardized_betas = w[:-1] / originanal_stds\n",
    "unstandardized_bias  = w[-1]-np.sum((original_means / originanal_stds) * w[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bias:  36.4595\n",
      "    CRIM:  -0.1080\n",
      "      ZN:   0.0464\n",
      "   INDUS:   0.0206\n",
      "    CHAS:   2.6867\n",
      "     NOX: -17.7666\n",
      "      RM:   3.8099\n",
      "     AGE:   0.0007\n",
      "     DIS:  -1.4756\n",
      "     RAD:   0.3060\n",
      "     TAX:  -0.0123\n",
      " PTRATIO:  -0.9527\n",
      "       B:   0.0093\n",
      "   LSTAT:  -0.5248\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o resultado\n",
    "print ('%8s: %8.4f' % ('bias', unstandardized_bias))\n",
    "for beta,varname in zip(unstandardized_betas, variables):\n",
    "    print ('%8s: %8.4f' % (varname, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importância dos Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo\n",
    "modelo = linear_model.LinearRegression(normalize = False, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo com dados não padronizados (em escalas diferentes)\n",
    "modelo.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.767 NOX\n",
      " 3.810 RM\n",
      " 2.687 CHAS\n",
      " 1.476 DIS\n",
      " 0.953 PTRATIO\n",
      " 0.525 LSTAT\n",
      " 0.306 RAD\n",
      " 0.108 CRIM\n",
      " 0.046 ZN\n",
      " 0.021 INDUS\n",
      " 0.012 TAX\n",
      " 0.009 B\n",
      " 0.001 AGE\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo os coeficientes e as variáveis\n",
    "for coef, var in sorted(zip(map(abs, modelo.coef_), dataset.columns[:-1]), reverse = True):\n",
    "    print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando os dados\n",
    "standardization = StandardScaler()\n",
    "Stand_coef_linear_reg = make_pipeline(standardization, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo com dados padronizados (na mesma escala)\n",
    "Stand_coef_linear_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3.744 LSTAT\n",
      " 3.104 DIS\n",
      " 2.674 RM\n",
      " 2.662 RAD\n",
      " 2.077 TAX\n",
      " 2.061 PTRATIO\n",
      " 2.057 NOX\n",
      " 1.082 ZN\n",
      " 0.928 CRIM\n",
      " 0.849 B\n",
      " 0.682 CHAS\n",
      " 0.141 INDUS\n",
      " 0.019 AGE\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo os coeficientes e as variáveis\n",
    "for coef, var in sorted(zip(map(abs, Stand_coef_linear_reg.steps[1][1].coef_), dataset.columns[:-1]), reverse = True):\n",
    "    print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression(normalize = False, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_est(X,y):\n",
    "    return r2_score(y, modelo.fit(X,y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente R2: 0.741\n"
     ]
    }
   ],
   "source": [
    "print ('Coeficiente R2: %0.3f' %  r2_est(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.056 LSTAT\n",
      " 0.044 RM\n",
      " 0.029 DIS\n",
      " 0.028 PTRATIO\n",
      " 0.011 NOX\n",
      " 0.011 RAD\n",
      " 0.006 B\n",
      " 0.006 ZN\n",
      " 0.006 CRIM\n",
      " 0.006 TAX\n",
      " 0.005 CHAS\n",
      " 0.000 INDUS\n",
      " 0.000 AGE\n"
     ]
    }
   ],
   "source": [
    "# Gera o impacto de cada atributo no R2\n",
    "r2_impact = list()\n",
    "for j in range(X.shape[1]):\n",
    "    selection = [i for i in range(X.shape[1]) if i!=j]\n",
    "    r2_impact.append(((r2_est(X,y) - r2_est(X.values[:,selection],y)), dataset.columns[j]))\n",
    "    \n",
    "for imp, varname in sorted(r2_impact, reverse = True):\n",
    "    print ('%6.3f %s' %  (imp, varname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo Previsões com o Modelo de Regressão Linear Múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset tem 506 observações com 14 variáveis cada uma.\n"
     ]
    }
   ],
   "source": [
    "# Formato do Dataset\n",
    "print(\"Boston housing dataset tem {} observações com {} variáveis cada uma.\".format(*dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando x e y\n",
    "# Usaremos como variáveis explanatórias somente as 4 variáveis mais relevantes\n",
    "X = dataset[['LSTAT', 'RM', 'DIS', 'PTRATIO']]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>PTRATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.98</td>\n",
       "      <td>6.575</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.14</td>\n",
       "      <td>6.421</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.03</td>\n",
       "      <td>7.185</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.94</td>\n",
       "      <td>6.998</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.33</td>\n",
       "      <td>7.147</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSTAT     RM     DIS  PTRATIO\n",
       "0   4.98  6.575  4.0900     15.3\n",
       "1   9.14  6.421  4.9671     17.8\n",
       "2   4.03  7.185  4.9671     17.8\n",
       "3   2.94  6.998  6.0622     18.7\n",
       "4   5.33  7.147  6.0622     18.7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em dados de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "modelo = LinearRegression(normalize = False, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o modelo\n",
    "modelo_v2 = modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347923449246607"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula a métrica R2 do nosso modelo\n",
    "r2_score(y_test, modelo_v2.fit(X_train, y_train).predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa Média de Ocupação Para a Casa: [33.65282404]\n"
     ]
    }
   ],
   "source": [
    "# Produz a matriz com os novos dados de entrada para a previsão\n",
    "LSTAT = 5\n",
    "RM = 8\n",
    "DIS = 6\n",
    "PTRATIO = 19\n",
    "\n",
    "# Lista com os valores das variáveis\n",
    "dados_nova_casa = [LSTAT, RM, DIS, PTRATIO]\n",
    "\n",
    "# Reshape\n",
    "Xp = np.array(dados_nova_casa).reshape(1, -1)\n",
    "\n",
    "# Previsão\n",
    "print(\"Taxa Média de Ocupação Para a Casa:\", modelo_v2.predict(Xp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
